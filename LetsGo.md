## **LetsGo: Large-Scale Garage Modeling and Rendering via LiDAR-Assisted Gaussian Primitives**

### 一、概要介绍

**1.研究背景：**

- 复杂的几何形状、低光照条件、各类反光、无纹理表面使得捕捉和渲染地下车库存在困难，频繁存在的障碍物和狭小的空间导致车库在空间上高度杂乱，使得建模过程更加复杂。
- 现有车库建模方法如SFM和MVS通常无法在这种复杂环境下提取到足够的特征点，无法建立估计相机姿态所需的准确特征对应关系。激光雷达SLAM的数据往往很稀疏，包含许多孔洞，这些孔洞会破坏渲染场景颜色外观所必需的高频纹理。
- NeRF计算开销大，训练时间长。3DGS最近的工作已经扩展到模拟大规模户外场景，但还是无法解决地下车库这种复杂场景



**2.创新点：**

- 设计了一种手持式极坐标扫描仪，结合IMU、LiDAR和鱼眼相机，可以提供稳健的特征对应关系用于相机位姿估计
- 用扫描仪扫描了八个车库，建立了第一个针对大型车库的数据集GarageWorld
- 引入了一种深度正则化，显著减少了浮动伪影

- 提出与LOD渲染配合的多分辨率3DGS表示方法，低分辨率提取粗略场景特征，高分辨率提取精细场景特征。并为每个级别的渲染采用了定制的缩放因子和随机分辨率级别训练方案来优化不同细节级别下的高斯分布（每轮训练时以一定概率随机选择不同的分辨率级别作为输入，每个分辨率级别对应独立的缩放因子）

- 开发了一个LOD查看器，比部署在3090上的3DGS查看器SIBR Viewers渲染快4倍,还提供了一个轻量级的web渲染器,支持各种笔记本和平板电脑的LOD渲染。

  

### **二、相关工作**

- 介绍SFM、SLAM、MVS，NeRF和3DGS领域内各种相关工作。

  

### **三、数据采集**

**1.采集设备：**

- 鱼眼相机：30FPS,6K分辨率，180°×180°视场。

- 激光雷达传感器：每秒采集260w个点，测量精度1~1.5cm，最大检测距离50m

- IMU传感器提供设备运动的加速度信息。在这里imu用来保证运动追踪的鲁棒性，LiDAR或鱼眼相机因低光、反光环境失效时，imu通过测量设备加速度推算设备的瞬时位置和朝向，保证扫描不中断，可以辅助去除动态模糊或填补运动信息空缺。

- 配备数据处理单元用于实时SLAM计算，可在手机上实时预览3D点云重建结果

  ![image-20250310152748135](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310152748135.png)

**2.采集策略：**

- 设计扫描轨迹以模拟驾车和停车，沿每条轨迹前后左右采4次数据

- 相机设置为自动曝光和自动ISO

- 各种防止过曝、欠曝、运动模糊，尽量保证采集区域照明条件一致的采集策略

  

**3.GarageWorld数据集**：

- 6个室内地下停车场由天花板上的荧光灯照亮，采集数据无特殊时段要求，1个多层室内车库部分由阳光照射，部分由室内灯光照射，清晨不开灯，在傍晚收集这个车库的数据。1个室外停车场位于购物中心顶部，白天室外的照明比室内强。晚上有限的昏暗路灯不足以满足摄影要求，在清晨进行数据采集。

**4.初始网格重建**：

- 在收集点云数据后，应用泊松重建将点云数据转换为网格。为了确保生成网格的准确性和完整性，作者将重建的网格与原始点云数据进行比较，删除不正确的面

### **四、激光雷达辅助的LOD高斯**

**1.采用激光雷达采集数据作为输入的高斯**：

- 考虑到原始扫描的点云包含噪声，我们使用均匀采样策略从重建的网格中重新采样一组新点，将重新采样得到的点和相机参数一起用于3DGS的训练，这样的数据是高质量的
- 引入一个深度正则化器，𝐷为渲染深度，d为高斯体在相机透视中的深度，α为不透明度，T为累积透明度。在这作者不直接取高斯体中心的μ作为深度。理由是：由于高斯形状和方向的变化，光线与高斯相交的精确点的深度偏离了其中心的深度。

![image-20250310161224366](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310161224366.png)

- 这是作者设计的高斯体与光线交点处的预期深度计算公式，

  ![image-20250318172607182](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250318172607182.png)

![image-20250310161243666](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310161243666.png)



- x0,x1 是光线与高斯体相交像素平面上的坐标，x2是沿射线方向的深度。在相机坐标系下，深度t需要进行一个归一化变换，

- 假设相机光心位于 (0,0,0)，成像平面位于 z=1处，则光线可以表示为 (x0,x1,1)，对于一个点 (x0,x1,x2)在光线空间中的深度 x2其实际深度应该按照光线方向进行归一化，使得它与世界坐标的测量一致。t=x2/l，表示实际相机坐标系下的深度，这里把高斯函数看作概率密度函数。

  ![image-20250318172821479](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250318172821479.png)

- t带入公式后，引入高斯体中心p和偏移量y=x-p，化简得到图中的公式(10)，第一项是高斯中心对深度计算的贡献，第二项是偏移量对深度计算的贡献

  ![image-20250318172720433](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250318172720433.png)

![image-20250310165538408](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310165538408.png)

- 展开是基于二元高斯分布的指数形式，拆解出沿y2方向的部分，然后根据给出的高斯积分公式带入得到图中公式(15)，B/2A代表高斯概率分布的偏移修正

![image-20250310171455856](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310171455856.png)

- Dk是激光雷达数据里面固定的捕获视图K的深度

- 总损失函数为RGB图像重建损失+深度计算的权重*深度计算的损失

  

**2.多分辨率表示**：

- 引入LOD，在初始化多分辨率高斯分布时为每个高斯分布分配一个LOD属性，以及其原始属性，如位置、球面调和系数和不透明度

- 设置点云的分辨率τ ，定义为点之间的最小距离，然后降采样，将τ 变成2τ ，点云最小距离变大，更加粗糙，画面精细度下降，LOD级别下降，原始的最精细级别设置为N=L-1,最粗糙的为N=0

- **第一遍遍历**

  - 创建八叉树结构。起始根节点LOD级别为0
  - 遍历所有子节点，为每个节点分配包围盒 B，子节点的LOD级别为当前节点LOD级别+1
  - 从不同LOD级别的.ply文件中加载点云，并将点云存储到到LOD级别对应的八叉树节点的包围盒B中。

  **第二遍遍历**

  - 再从根节点开始遍历八叉树,删除空节点，减少不必要的存储。
  - 将当前节点的点云数据写入`octree.bin`文件，将层次信息（包围盒`B`、点云数量 `numPoints`、数据偏移 `byteOffset`、数据大小 `byteSize`）写入 `hierarchy.bin` 文件，更新数据偏移 `byteOffset`=`byteOffset+byteSize`

**3.相应的多分辨率训练策略**

![image-20250310195335828](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310195335828.png)



- βs和Smax是超参数，分别为√2 和4.0，Sk是阈值缩放因子，当位置梯度或方差大于𝑠 · 𝜎𝑝𝑜𝑠 and 𝑠 · 𝜎𝑣𝑎的时候，就会克隆或分裂，当LOD级别高时，l比较的大，阈值比较的小，更容易分裂或克隆，这是同一场景下的LOD策略

![image-20250310200114662](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310200114662.png)



- dmax是点云数据中到当前训练视点最大的点的深度，clamp限制L在这个范围内，距离为深度0时最精细，为LOD级别为L-1

  

**4.轻量级Web查看器**

- 主流轻量级高斯渲染器将高斯体同时加载到VRAM中，而作者则是动态加载必要的数据存入内存，先预先将最低分辨率级别高斯体加载到内存中，再遍历八叉树，确保每个节点的可见性，第二次遍历八叉树时按分辨率级别从低到高遍历将高斯体加载入缓冲区中，直到遍历完全部节点或者可容纳加载的高斯体数量达到最大时，用新加载的高分辨率高斯替换预加载的高斯来更新缓冲区

  

### **五、实验部分**

**1.训练细节**：

- 在A6000上训练，缩放学习率设置为0.0015，高斯基元初始学习率设为0.000016，球谐函数为二阶，深度参数𝜆设置为0.8，禁用不透明度重置，避免训练过程中过早消除不透明的点云。延迟高斯稠密化步骤到75000轮后，在初期的低LOD级别时减少不必要的点增加。整个过程持续时间大概在12到16个小时内
- 把每个场景分成3到10个块，每个块向外扩展30%，相邻块之间有重叠部分，解决重建边缘丢失的问题，还可以减少边界伪影，使得拼接的效果更加平滑。
- 高斯框架只能渲染针孔相机的图像，将鱼眼图像投影到一个半球表面，再从顶底左右前五个方向使用虚拟相机重新投影，得到五张针孔相机图像。



**2.定量结果对比**：

- 作者使用GarageWorld、KITTI-360、ScanNet++作为数据集，其中10%图像作为测试集，90%作为训练集，带星号的是用LiDAR的点云而不是SFM点云进行初始化。

  ![image-20250310205240870](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310205240870.png)

**3.定性结果对比**：

- 对不同输入点云质量的定性消融研究表明，使用从网格中采样的点云可以显著提高渲染质量

![image-20250310205730090](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310205730090.png)

**4.消融研究**：

- 评估了不同点云质量对重建结果的影响，使用以不同间隔从网格中采样的点云，以及以4cm间隔下采样的原始LiDAR点云

![image-20250310211227906](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310211227906.png)

- 取消了LOD策略进行对比，发现LOD策略确实能显著降低高斯体在排序、投影和累积操作方面的复杂度，从而加快渲染速度

- 直接应用LOD渲染策略而取消使用RRL随机分辨率的训练策略，会导致特定场景区域在某些分辨率水平上的过拟合

![image-20250310213753328](C:\Users\86138\AppData\Roaming\Typora\typora-user-images\image-20250310213753328.png)

### **六、应用场景**

- 支持各种自动驾驶算法训练和提供自动驾驶虚拟环境
- 实时定位和导航
- 增强视觉特效制作

### **七、不足之处**

- 可探索使用更轻的设备对大规模场景进行采集数据的可能性
- 探索修改光照条件的可能性，现有渲染管线不支持修改光照条件，拍摄采集数据的过程需要精心的设计
- 未来可研究高斯核的流式传输方法，以实现大规模场景数据的分布式储存和场景实时渲染。
- 作者未来计划研究基于3DGS表示的大规模场景生成，因为其很容易集成到现有的计算机图形工作流程中并实现卓越的渲染效果

### **八、结论**

- 手持Polar设备
- GarageWorld数据集
- LiDAR点云辅助3DGS
- 基于LOD的渲染技术